
[INFO] Patched matplotlib.Axes.errorbar to abs() negative yerr for robustness.

[INFO] Using AUTO device selection.
Global seed set to 42
======================================================================
Training TFT: exp001_baseline
======================================================================
Configuration saved to: experiments/exp001_baseline/config.json

Loading data splits...
Train: 6066 samples
Val: 1300 samples
Test: 1300 samples

Preparing TimeSeriesDataSet...
Batches per epoch: 94

Initializing model...
Model parameters: 66,975
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs

Starting training...
Checkpoints will be saved to: experiments/exp001_baseline/checkpoints/
Logs will be saved to: experiments/exp001_baseline/logs/

You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name                               | Type                            | Params
----------------------------------------------------------------------------------------
0  | loss                               | QuantileLoss                    | 0     
1  | logging_metrics                    | ModuleList                      | 0     
2  | input_embeddings                   | MultiEmbedding                  | 0     
3  | prescalers                         | ModuleDict                      | 192   
4  | static_variable_selection          | VariableSelectionNetwork        | 1.8 K 
5  | encoder_variable_selection         | VariableSelectionNetwork        | 9.8 K 
6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.8 K 
7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K 
8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K 
9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K 
10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K 
11 | lstm_encoder                       | LSTM                            | 8.4 K 
12 | lstm_decoder                       | LSTM                            | 8.4 K 
13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K 
14 | post_lstm_add_norm_encoder         | AddNorm                         | 64    
15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K 
16 | multihead_attn                     | InterpretableMultiHeadAttention | 3.2 K 
17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K 
18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K 
19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K 
20 | output_layer                       | Linear                          | 231   
----------------------------------------------------------------------------------------
67.0 K    Trainable params
0         Non-trainable params
67.0 K    Total params
0.268     Total estimated model params size (MB)
Epoch 0: val_loss=N/A
Epoch 0: val_loss=0.13710516691207886
Epoch 0: train_loss=0.6329875588417053
Epoch 1: val_loss=0.17754539847373962
Epoch 1: train_loss=0.46941837668418884
Epoch 2: val_loss=0.19862626492977142
Epoch 2: train_loss=0.4519249200820923
Epoch 3: val_loss=0.22132885456085205
Epoch 3: train_loss=0.44510021805763245
Epoch 4: val_loss=0.23354317247867584
Epoch 4: train_loss=0.4398476481437683
Epoch 5: val_loss=0.22474125027656555
Epoch 5: train_loss=0.4352799355983734
Epoch 6: val_loss=0.22140541672706604
Epoch 6: train_loss=0.4326286315917969
Epoch 7: val_loss=0.21245762705802917
Epoch 7: train_loss=0.4300229847431183
Epoch 8: val_loss=0.21395176649093628
Epoch 8: train_loss=0.4293000102043152
Epoch 9: val_loss=0.2083074152469635
Epoch 9: train_loss=0.42841821908950806
Epoch 10: val_loss=0.20209696888923645
Epoch 10: train_loss=0.4282897114753723


======================================================================
Training complete!
======================================================================

Best model checkpoint: experiments/exp001_baseline/checkpoints/tft-epoch=00-val_loss=0.1371.ckpt
Best validation loss: 0.137105
