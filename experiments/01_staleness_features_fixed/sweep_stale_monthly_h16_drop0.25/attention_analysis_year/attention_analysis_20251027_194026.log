Logging to: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_analysis_20251027_194026.log
Analysis started at: 2025-10-27 19:40:26
======================================================================
Experiment: 01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25
Output directory: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year
Using best checkpoint: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/checkpoints/tft-epoch=49-val_loss=2.7655.ckpt

Loading data...
Loading test data from: data/splits/fixed/core_proposal_monthly_fixed_test.csv
Detected staleness features in config, adding to data...
  Train samples: 292
  Test samples: 63

Preparing test dataset...
Test dataset size after filtering: 51

Loading model...
Loading model from: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/checkpoints/tft-epoch=49-val_loss=2.7655.ckpt

Extracting attention patterns...
Extracting attention patterns...
Total batches to process: 1

Total predictions: 51
Total actuals: 51
Attention shape: (51, 12)
Encoder variables shape: (51, 7)

Prediction period: 2021-08-31T00:00:00.000000000 to 2025-10-31T00:00:00.000000000
Total predictions: 51

Creating temporal periods:
  2021: 5 samples
  2022: 12 samples
  2023: 12 samples
  2024: 12 samples
  2025: 10 samples

Attention over 12 encoder timesteps

Analyzing attention patterns by period...

Comparing attention patterns across periods...

Creating visualizations...
Saved attention heatmap: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_heatmap.png
Saved attention trends: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_trends.png
Saved feature importance comparison: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/temporal_attention_comparison.png

Saving results...
Saved results: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_analysis_results.json

======================================================================
ATTENTION ANALYSIS SUMMARY
======================================================================

Per-Period Statistics:
----------------------------------------------------------------------

2021:
  Samples: 5
  Entropy: 2.4817 ± 0.0005
  Concentration: 0.0836
  Top 5 features:
    t-4                            0.0895
    t-5                            0.0894
    t-3                            0.0883
    t-6                            0.0883
    t-2                            0.0857

2022:
  Samples: 12
  Entropy: 2.4748 ± 0.0050
  Concentration: 0.0845
  Top 5 features:
    t-12                           0.1028
    t-11                           0.0972
    t-10                           0.0927
    t-9                            0.0889
    t-8                            0.0857

2023:
  Samples: 12
  Entropy: 2.4776 ± 0.0048
  Concentration: 0.0840
  Top 5 features:
    t-1                            0.0958
    t-2                            0.0932
    t-3                            0.0915
    t-4                            0.0899
    t-5                            0.0871

2024:
  Samples: 12
  Entropy: 2.4783 ± 0.0028
  Concentration: 0.0834
  Top 5 features:
    t-12                           0.0858
    t-7                            0.0852
    t-9                            0.0849
    t-8                            0.0849
    t-6                            0.0843

2025:
  Samples: 10
  Entropy: 2.4751 ± 0.0029
  Concentration: 0.0835
  Top 5 features:
    t-12                           0.0922
    t-11                           0.0887
    t-10                           0.0858
    t-9                            0.0841
    t-8                            0.0838

----------------------------------------------------------------------
Period Comparisons:
----------------------------------------------------------------------

2021_vs_2022:
  Cosine similarity: 0.9861
  L2 distance: 0.0484
  Entropy change: -0.0069
  Concentration change: 0.0009

2021_vs_2023:
  Cosine similarity: 0.9980
  L2 distance: 0.0184
  Entropy change: -0.0042
  Concentration change: 0.0004

2021_vs_2024:
  Cosine similarity: 0.9974
  L2 distance: 0.0209
  Entropy change: -0.0034
  Concentration change: -0.0002

2021_vs_2025:
  Cosine similarity: 0.9953
  L2 distance: 0.0280
  Entropy change: -0.0067
  Concentration change: -0.0001

2022_vs_2023:
  Cosine similarity: 0.9794
  L2 distance: 0.0589
  Entropy change: 0.0028
  Concentration change: -0.0005

2022_vs_2024:
  Cosine similarity: 0.9948
  L2 distance: 0.0296
  Entropy change: 0.0035
  Concentration change: -0.0011

2022_vs_2025:
  Cosine similarity: 0.9971
  L2 distance: 0.0221
  Entropy change: 0.0003
  Concentration change: -0.0010

2023_vs_2024:
  Cosine similarity: 0.9941
  L2 distance: 0.0314
  Entropy change: 0.0008
  Concentration change: -0.0006

2023_vs_2025:
  Cosine similarity: 0.9918
  L2 distance: 0.0370
  Entropy change: -0.0025
  Concentration change: -0.0005

2024_vs_2025:
  Cosine similarity: 0.9994
  L2 distance: 0.0102
  Entropy change: -0.0033
  Concentration change: 0.0001

======================================================================

Analysis complete!
Results saved to: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year
  - attention_analysis_results.json
  - attention_heatmap.png
  - attention_trends.png
  - temporal_attention_comparison.png
