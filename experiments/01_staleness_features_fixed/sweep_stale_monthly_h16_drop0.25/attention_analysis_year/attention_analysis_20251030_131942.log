Logging to: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_analysis_20251030_131942.log
Analysis started at: 2025-10-30 13:19:42
======================================================================
Experiment: 01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25
Output directory: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year
Using best checkpoint: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/checkpoints/tft-epoch=99-val_loss=1.8725.ckpt

Loading data...
Loading test data from: data/splits/fixed/core_proposal_monthly_fixed_test.csv
Detected staleness features in config, adding to data...
  Train samples: 292
  Test samples: 63

Preparing test dataset...
Test dataset size after filtering: 51

Loading model...
Loading model from: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/checkpoints/tft-epoch=99-val_loss=1.8725.ckpt
Model moved to device: cuda

Extracting attention patterns...
Extracting attention patterns...
Total batches to process: 1

Total predictions: 51
Total actuals: 51
Attention shape: (51, 12)
Encoder variables shape: (51, 7)

Prediction period: 2021-08-31T00:00:00.000000000 to 2025-10-31T00:00:00.000000000
Total predictions: 51

Creating temporal periods:
  2021: 5 samples
  2022: 12 samples
  2023: 12 samples
  2024: 12 samples
  2025: 10 samples

Attention over 12 encoder timesteps

Analyzing attention patterns by period...

Comparing attention patterns across periods...

Creating visualizations...
Saved attention heatmap: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_heatmap.png
Saved attention trends: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_trends.png
Saved feature importance comparison: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/temporal_attention_comparison.png

Saving results...
Saved results: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year/attention_analysis_results.json

======================================================================
ATTENTION ANALYSIS SUMMARY
======================================================================

Per-Period Statistics:
----------------------------------------------------------------------

2021:
  Samples: 5
  Entropy: 2.4816 Â± 0.0005
  Concentration: 0.0838
  Top 5 features:
    t-2                            0.0913
    t-3                            0.0907
    t-1                            0.0904
    t-4                            0.0898
    t-5                            0.0875

2022:
  Samples: 12
  Entropy: 2.4829 Â± 0.0007
  Concentration: 0.0835
  Top 5 features:
    t-12                           0.0897
    t-11                           0.0871
    t-10                           0.0863
    t-9                            0.0859
    t-8                            0.0853

2023:
  Samples: 12
  Entropy: 2.4845 Â± 0.0001
  Concentration: 0.0833
  Top 5 features:
    t-12                           0.0847
    t-1                            0.0840
    t-4                            0.0838
    t-3                            0.0837
    t-2                            0.0837

2024:
  Samples: 12
  Entropy: 2.4754 Â± 0.0107
  Concentration: 0.0834
  Top 5 features:
    t-12                           0.0872
    t-9                            0.0852
    t-7                            0.0852
    t-8                            0.0851
    t-6                            0.0850

2025:
  Samples: 10
  Entropy: 2.4699 Â± 0.0094
  Concentration: 0.0834
  Top 5 features:
    t-5                            0.0858
    t-2                            0.0855
    t-4                            0.0854
    t-1                            0.0853
    t-3                            0.0850

----------------------------------------------------------------------
Period Comparisons:
----------------------------------------------------------------------

2021_vs_2022:
  Cosine similarity: 0.9929
  L2 distance: 0.0345
  Entropy change: 0.0013
  Concentration change: -0.0003

2021_vs_2023:
  Cosine similarity: 0.9973
  L2 distance: 0.0211
  Entropy change: 0.0028
  Concentration change: -0.0005

2021_vs_2024:
  Cosine similarity: 0.9947
  L2 distance: 0.0298
  Entropy change: -0.0062
  Concentration change: -0.0004

2021_vs_2025:
  Cosine similarity: 0.9979
  L2 distance: 0.0188
  Entropy change: -0.0117
  Concentration change: -0.0004

2022_vs_2023:
  Cosine similarity: 0.9989
  L2 distance: 0.0137
  Entropy change: 0.0016
  Concentration change: -0.0002

2022_vs_2024:
  Cosine similarity: 0.9997
  L2 distance: 0.0065
  Entropy change: -0.0075
  Concentration change: -0.0001

2022_vs_2025:
  Cosine similarity: 0.9981
  L2 distance: 0.0176
  Entropy change: -0.0130
  Concentration change: -0.0001

2023_vs_2024:
  Cosine similarity: 0.9995
  L2 distance: 0.0094
  Entropy change: -0.0091
  Concentration change: 0.0001

2023_vs_2025:
  Cosine similarity: 0.9998
  L2 distance: 0.0054
  Entropy change: -0.0146
  Concentration change: 0.0000

2024_vs_2025:
  Cosine similarity: 0.9988
  L2 distance: 0.0143
  Entropy change: -0.0055
  Concentration change: -0.0000

======================================================================

Analysis complete!
Results saved to: experiments/01_staleness_features_fixed/sweep_stale_monthly_h16_drop0.25/attention_analysis_year
  - attention_analysis_results.json
  - attention_heatmap.png
  - attention_trends.png
  - temporal_attention_comparison.png
